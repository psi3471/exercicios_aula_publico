{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abrir o notebook no Google Colab, altere o domínio `github.com` para `githubtocolab.com`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Para praticar programação, é importante que você erre, leia as mensagens de erro e tente corrigí-los.\n",
    "    \n",
    "Dessa forma, no Google Colab, é importante que você DESATIVE OS RECURSOS DE AUTOCOMPLETAR:\n",
    "\n",
    "- Menu Ferramentas -> Configurações\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Mostrar sugestões de preenchimento de código com base no contexto\"\n",
    "\n",
    "Na versão em inglês:\n",
    "\n",
    "- Menu Tools -> Settings\n",
    "- Na janela que é aberta:\n",
    "  - Seção Editor -> Desativar \"Show context-powered code completions\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSI3471 - Aula de Exercícios 07\n",
    "\n",
    "# CNN com PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue a implementação de uma rede CNN para resolver o problema de classificação de imagens de dígitos numéricos manuscritos do banco de dados [MNIST](https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Execute o código e verifique os resultados. Depois, modifique os hiperparâmetros e veja o efeito na acurácia.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando com a importação da bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ajustando o valor dos hiperparâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajuste de hiperparâmetros\n",
    "\n",
    "# passo de adaptação\n",
    "eta = 0.01\n",
    "\n",
    "# Tamanho do mini-batch\n",
    "Nb = 64\n",
    "\n",
    "# Tamanho do mini-batch usado no teste\n",
    "Nb_test = 1000\n",
    "\n",
    "# Número de épocas\n",
    "Ne = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O PyTorch tem algumas rotinas para carregar bancos de dados clássicos. Vamos usar essas rotinas para carregar o MNIST. Com o código abaixo, os dados vão ser obtidos da internet e gravados no local indicado por `dir_data`, em uma pasta chamada `data`.\n",
    "\n",
    "Além disso, vamos criar dois objetos `DataLoader`, para treinamento e teste, que vão se encarregar de ler os dados em partes e misturá-los:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-stdout"
    ]
   },
   "outputs": [],
   "source": [
    "dir_data = \"~/temp\"\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        dir_data,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(            \n",
    "            [transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=Nb,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        dir_data,\n",
    "        train=False,\n",
    "        transform=transforms.Compose(            \n",
    "            [transforms.ToTensor()]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=Nb_test,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale notar alguns detalhes sobre o código anterior:\n",
    "\n",
    " - o `DataLoader` de treinamento é criado com `train=True` e o de teste, com `train=False`, o que garante que não haja dados em comum entre os dois conjuntos;\n",
    " - É feita a configuração de uma transformação de dados ao carregá-los. Para isso, é criado um objeto do tipo `transforms.Compose`, que permite encadear uma série de transformações a serem aplicadas às imagens, durante o carregamento. Nesse caso, a transformação tem uma única etapa que consistem em converter os valores obtidos para um tensor do PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mostrar algumas imagens do dataset usando o DataLoader que criamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "O modelo é definido por meio de uma classe que herda de `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Necessário chamar __init__() da classe mãe\n",
    "        super().__init__()\n",
    "        \n",
    "        # Camada convolucional, seguida de ReLU e Pooling\n",
    "        # Entra uma imagem 28x28. Com filtro 5x5, padding de 2\n",
    "        # e stride 1, a saída também tem 28x28. Após o pooling,\n",
    "        # a saída fica com 14x14. A entrada tem 1 canal e a\n",
    "        # saída tem 16.\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        \n",
    "        # Camada convolucional\n",
    "        # Entrada 14x14, saída 7x7 após o pooling.\n",
    "        # 16 canais de entrada e 32 de saída.\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        \n",
    "        # Camada totalmente conectada\n",
    "        # Na entrada, há 32 canais de 7x7 elementos\n",
    "        # e a saída tem 10 neurônios.\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Aplica primeira camada convolucional\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Aplica segunda camada convolucional\n",
    "        x = self.conv2(x)        \n",
    "        \n",
    "        # Transforma os tensores 32x7x7 em\n",
    "        # vetores para serem usados na entrada da\n",
    "        # camada totalmente conectada. Vale notar\n",
    "        # que a primeira dimensão dos tensores de\n",
    "        # dados é usada para representar os diversos\n",
    "        # elementos de um batch, por isso permanece\n",
    "        # inalterada.\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        \n",
    "        # Calcula a saída e retorna\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando o modelo e definindo a função custo e o otimizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instanciando modelo\n",
    "model = Model().to(device)\n",
    "\n",
    "# Função custo para treinamento\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale notar que a função custo `CrossEntropyLoss` espera comparar um vetor de $C$ posições com um número de $0$ a $C-1$, conforme descrito na [documentação](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Além disso, é esperado que os elementos do vetor representem a *evidência*, ou seja os valores chamados de *logits*, que não são normalizados e podem valer de $-\\infty$ a $\\infty$. Por isso, na saída da rede, não é usada a função *Softmax*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o *loop* de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista usada para guardar o valor da função custo ao longo das iterações\n",
    "losses = []\n",
    "\n",
    "# Loop das épocas\n",
    "for epoch in range(Ne):\n",
    "    # Loop dos mini batches\n",
    "    for n, (X, d) in enumerate(train_loader):\n",
    "        # Envia os dados para a GPU, caso ela exista\n",
    "        X = X.to(device=device)\n",
    "        d = d.to(device=device)\n",
    "\n",
    "        # Ajuste de dimensões\n",
    "        # (elementos do mini batch x 1 canal x 28 x 28)\n",
    "        X = X.view(-1, 1, 28, 28)\n",
    "\n",
    "        # Coloca o modelo em modo treinamento\n",
    "        model.train()\n",
    "\n",
    "        # Zera informações de gradientes\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calcula a saída\n",
    "        y = model(X)\n",
    "\n",
    "        # Calcula o valor da função custo\n",
    "        loss = loss_function(y, d)\n",
    "\n",
    "        # Calcula os gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os pesos do modelo\n",
    "        optimizer.step()\n",
    "\n",
    "        # Armazena o valor da função custo\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Mostra o valor da função custo a cada 100 iterações\n",
    "        if n % 100 == 0:\n",
    "            N_all = len(train_loader.dataset)\n",
    "            n_ex = n * len(X)\n",
    "            p = 100. * n / len(train_loader)\n",
    "            print(\n",
    "                f\"Época: {epoch} [{n_ex}/{N_all} ({p:.0f}%)]\\tLoss: {loss:.6f}\"\n",
    "            )            \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando modelo com os dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variável usada para contabilizar o número de acertos\n",
    "correct = 0\n",
    "\n",
    "# Loop dos mini batches\n",
    "for n, (X, d) in enumerate(test_loader):\n",
    "    # Envia os dados para a GPU, caso ela exista\n",
    "    X = X.to(device=device)\n",
    "    d = d.to(device=device)\n",
    "\n",
    "    # Ajuste de dimensões\n",
    "    X = X.view(-1, 1, 28, 28)\n",
    "\n",
    "    # Coloca o modelo em modo de inferência\n",
    "    model.eval()\n",
    "\n",
    "    # Calcula a saída\n",
    "    y = model(X)\n",
    "\n",
    "    # Cálculo do número de acertos:\n",
    "    # 1) Obtém o índice do elemento máximo para cada exemplo do minibatch\n",
    "    pred = torch.max(y, 1, keepdim=True)[1]     \n",
    "    # 2) Conta o número de acertos e acumula na variável correct\n",
    "    # pred.eq(d.view_as(pred)) é um tensor booleano. Dessa forma, o número de\n",
    "    # acertos é obtido somando seus elementos. Valores True são tratados como 1. \n",
    "    correct += pred.eq(d.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "# Mostra o desempenho obtido no teste    \n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(f\"Acurácia: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
